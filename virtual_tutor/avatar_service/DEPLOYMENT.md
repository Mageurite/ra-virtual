# Avatar Service éƒ¨ç½²æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

Avatar Service æ˜¯ Virtual Tutor ç³»ç»Ÿçš„ AI æ¨ç†å¼•æ“ï¼Œæä¾›ï¼š
- **LLM å¯¹è¯æœåŠ¡** (Ollama)
- **Avatar ç®¡ç†æœåŠ¡** (Mageurite é›†æˆ)
- **WebRTC å®æ—¶é€šä¿¡ä»£ç†**

æœ¬æœåŠ¡å®Œå…¨æ— çŠ¶æ€ï¼Œæ— éœ€æ•°æ®åº“ï¼Œå¯ç‹¬ç«‹éƒ¨ç½²å’Œæ‰©å±•ã€‚

---

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux / macOS / Windows
- **Python**: 3.10+ 
- **å†…å­˜**: æœ€ä½ 8GB (æ¨è 16GB+)
- **GPU**: å¯é€‰ (æ¨èç”¨äº Ollama LLM æ¨ç†)

### ä¾èµ–æœåŠ¡
1. **Ollama** (LLM æ¨ç†å¼•æ“) - å¿…éœ€
   - ä¸‹è½½: https://ollama.ai/download
   - ç«¯å£: `11434` (é»˜è®¤)

2. **Mageurite Lip-Sync Service** (Avatar ç”Ÿæˆ) - å¯é€‰
   - ç«¯å£: `8615` (é»˜è®¤)
   - ä»“åº“: mageurite_virtual_tutor/lip-sync

3. **Mageurite TTS Service** (è¯­éŸ³åˆæˆ) - å¯é€‰
   - ç«¯å£: `8604` (é»˜è®¤)
   - ä»“åº“: mageurite_virtual_tutor/tts

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### 1. å…‹éš†ä»£ç 
```bash
cd virtual_tutor/avatar_service
```

### 2. åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ (æ¨è)
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate  # Linux/macOS
# æˆ–
venv\Scripts\activate     # Windows
```

### 3. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 4. é…ç½®ç¯å¢ƒå˜é‡
```bash
# å¤åˆ¶ç¤ºä¾‹é…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
nano .env
```

**å¿…éœ€é…ç½®**:
```bash
# Ollama æœåŠ¡åœ°å€
OLLAMA_BASE_URL=http://localhost:11434

# LLM æ¨¡å‹ï¼ˆç¡®ä¿å·²ä¸‹è½½ï¼‰
LLM_DEFAULT_MODEL=mistral-nemo:12b-instruct-2407-fp16

# æœåŠ¡ç«¯å£
PORT=8001
```

**å¯é€‰é…ç½®** (å¦‚æœä½¿ç”¨ Avatar åŠŸèƒ½):
```bash
# Mageurite æœåŠ¡åœ°å€
LIPSYNC_SERVICE_URL=http://localhost:8615
TTS_SERVICE_URL=http://localhost:8604
```

### 5. ä¸‹è½½ LLM æ¨¡å‹
```bash
# ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ
ollama serve &

# ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
ollama pull mistral-nemo:12b-instruct-2407-fp16

# æˆ–ä½¿ç”¨æ›´è½»é‡çš„æ¨¡å‹
ollama pull llama3.1:8b-instruct-q4_K_M
```

### 6. å¯åŠ¨æœåŠ¡
```bash
# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
uvicorn main:app --reload --port 8001

# ç”Ÿäº§æ¨¡å¼
uvicorn main:app --host 0.0.0.0 --port 8001 --workers 4
```

### 7. éªŒè¯éƒ¨ç½²
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8001/health

# æµ‹è¯• LLM
curl -X POST http://localhost:8001/api/chat/completion \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, how are you?"}'

# æŸ¥çœ‹ API æ–‡æ¡£
open http://localhost:8001/docs
```

---

## ğŸ³ Docker éƒ¨ç½²

### ä½¿ç”¨ Dockerfile
```bash
# æ„å»ºé•œåƒ
docker build -t avatar-service:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name avatar-service \
  -p 8001:8001 \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  avatar-service:latest
```

### ä½¿ç”¨ Docker Compose
åˆ›å»º `docker-compose.yml`:
```yaml
version: '3.8'

services:
  avatar-service:
    build: .
    ports:
      - "8001:8001"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - LIPSYNC_SERVICE_URL=http://mageurite-lipsync:8615
      - TTS_SERVICE_URL=http://mageurite-tts:8604
    depends_on:
      - ollama
  
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama

volumes:
  ollama-data:
```

å¯åŠ¨:
```bash
docker-compose up -d
```

---

## ğŸ”¥ ç”Ÿäº§éƒ¨ç½²

### ä½¿ç”¨ Gunicorn (æ¨è)
```bash
# å®‰è£… Gunicorn
pip install gunicorn uvicorn[standard]

# å¯åŠ¨æœåŠ¡
gunicorn main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8001 \
  --timeout 300 \
  --access-logfile - \
  --error-logfile -
```

### ä½¿ç”¨ Systemd æœåŠ¡
åˆ›å»º `/etc/systemd/system/avatar-service.service`:
```ini
[Unit]
Description=Avatar AI Service
After=network.target

[Service]
Type=notify
User=www-data
WorkingDirectory=/opt/virtual_tutor/avatar_service
Environment="PATH=/opt/virtual_tutor/avatar_service/venv/bin"
ExecStart=/opt/virtual_tutor/avatar_service/venv/bin/gunicorn main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8001
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡:
```bash
sudo systemctl daemon-reload
sudo systemctl enable avatar-service
sudo systemctl start avatar-service
sudo systemctl status avatar-service
```

### Nginx åå‘ä»£ç†
```nginx
server {
    listen 80;
    server_name avatar.yourdomain.com;

    location / {
        proxy_pass http://127.0.0.1:8001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # WebSocket æ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # è¶…æ—¶è®¾ç½®ï¼ˆLLM æ¨ç†å¯èƒ½è¾ƒæ…¢ï¼‰
        proxy_read_timeout 300s;
        proxy_connect_timeout 300s;
    }
}
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹é€‰æ‹©
æ ¹æ®ç¡¬ä»¶é€‰æ‹©åˆé€‚çš„ LLM æ¨¡å‹:

| æ¨¡å‹ | å‚æ•°é‡ | å†…å­˜éœ€æ±‚ | æ¨ç†é€Ÿåº¦ | è´¨é‡ |
|------|--------|----------|----------|------|
| `llama3.1:8b-instruct-q4_K_M` | 8B | ~5GB | å¿« | è‰¯å¥½ |
| `mistral-nemo:12b-instruct-2407-fp16` | 12B | ~25GB | ä¸­ç­‰ | ä¼˜ç§€ |
| `llama3.1:70b` | 70B | ~40GB | æ…¢ | æä½³ |

### 2. Worker æ•°é‡
```bash
# CPU å¯†é›†å‹å·¥ä½œ
workers = (CPU æ ¸å¿ƒæ•° Ã— 2) + 1

# ç¤ºä¾‹ï¼š8 æ ¸ CPU
gunicorn main:app --workers 17
```

### 3. ç¼“å­˜ä¼˜åŒ–
åœ¨ `.env` ä¸­é…ç½®:
```bash
# å¯ç”¨æ¨¡å‹é¢„åŠ è½½
OLLAMA_KEEP_ALIVE=24h

# ç¦ç”¨ä¸å¿…è¦çš„åŠŸèƒ½
GUARDRAIL_ENABLED=false
RAG_ENABLED=false
```

---

## ğŸ” å¥åº·ç›‘æ§

### API ç«¯ç‚¹
```bash
# æœåŠ¡å¥åº·
GET /health

# LLM å¥åº·
GET /api/chat/health

# Avatar æœåŠ¡å¥åº·
GET /api/avatar/health
```

### ç›‘æ§è„šæœ¬
åˆ›å»º `monitor.sh`:
```bash
#!/bin/bash
AVATAR_URL="http://localhost:8001"

# æ£€æŸ¥æœåŠ¡
if curl -sf "$AVATAR_URL/health" > /dev/null; then
    echo "âœ… Avatar Service: OK"
else
    echo "âŒ Avatar Service: DOWN"
    # å‘é€å‘Šè­¦...
fi

# æ£€æŸ¥ Ollama
if curl -sf "http://localhost:11434/api/tags" > /dev/null; then
    echo "âœ… Ollama: OK"
else
    echo "âŒ Ollama: DOWN"
fi
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: å¯¼å…¥é”™è¯¯ `ModuleNotFoundError: No module named 'langchain_ollama'`
**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install -r requirements.txt
# æˆ–å•ç‹¬å®‰è£…
pip install langchain-ollama langchain-core
```

### é—®é¢˜ 2: Ollama è¿æ¥å¤±è´¥
**æ£€æŸ¥**:
```bash
# æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags

# å¯åŠ¨ Ollama
ollama serve
```

### é—®é¢˜ 3: LLM å“åº”æ…¢
**ä¼˜åŒ–**:
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull llama3.1:8b

# æˆ–ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
ollama pull mistral-nemo:12b-q4_K_M
```

### é—®é¢˜ 4: ç«¯å£è¢«å ç”¨
**è§£å†³**:
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
lsof -i :8001

# æˆ–æ›´æ”¹ç«¯å£
uvicorn main:app --port 8002
```

### é—®é¢˜ 5: Avatar Service æ— æ³•è¿æ¥åˆ° Mageurite
**æ£€æŸ¥**:
```bash
# æµ‹è¯• Lip-Sync æœåŠ¡
curl http://localhost:8615/avatar/get_avatars

# æµ‹è¯• TTS æœåŠ¡
curl http://localhost:8604/health
```

---

## ğŸ“ˆ æ‰©å±•éƒ¨ç½²

### æ°´å¹³æ‰©å±• (å¤šå®ä¾‹)
```bash
# å®ä¾‹ 1
uvicorn main:app --port 8001 &

# å®ä¾‹ 2
uvicorn main:app --port 8002 &

# å®ä¾‹ 3
uvicorn main:app --port 8003 &
```

ä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨ (Nginx):
```nginx
upstream avatar_backend {
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
}

server {
    location / {
        proxy_pass http://avatar_backend;
    }
}
```

### å‚ç›´æ‰©å±• (GPU åŠ é€Ÿ)
```bash
# é…ç½® Ollama ä½¿ç”¨ GPU
ollama serve

# éªŒè¯ GPU ä½¿ç”¨
nvidia-smi
```

---

## ğŸ” å®‰å…¨å»ºè®®

1. **ç½‘ç»œéš”ç¦»**
   - Avatar Service åº”è¯¥åœ¨å†…ç½‘è¿è¡Œ
   - ä»…å…è®¸ Web Backend è®¿é—®
   - ä½¿ç”¨é˜²ç«å¢™é™åˆ¶ç«¯å£è®¿é—®

2. **æ—¥å¿—ç®¡ç†**
   ```bash
   # é…ç½®æ—¥å¿—è½®è½¬
   gunicorn main:app \
     --access-logfile /var/log/avatar/access.log \
     --error-logfile /var/log/avatar/error.log
   ```

3. **é™æµ**
   ```python
   # ä½¿ç”¨ slowapi é™æµ
   from slowapi import Limiter
   from slowapi.util import get_remote_address
   
   limiter = Limiter(key_func=get_remote_address)
   app.state.limiter = limiter
   ```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [README.md](README.md) - æœåŠ¡ä»‹ç»
- [Architecture Overview](../ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„
- [API Documentation](http://localhost:8001/docs) - æ¥å£æ–‡æ¡£
- [Ollama Documentation](https://ollama.ai/docs) - Ollama å®˜æ–¹æ–‡æ¡£

---

## ğŸ’¬ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹æ—¥å¿—: `tail -f /var/log/avatar/error.log`
2. æ£€æŸ¥å¥åº·çŠ¶æ€: `curl http://localhost:8001/health`
3. æŸ¥çœ‹ API æ–‡æ¡£: http://localhost:8001/docs
4. æäº¤ Issue: GitHub é¡¹ç›®ä»“åº“

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0.0** (2025-12-18)
  - åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
  - LLM å¯¹è¯æœåŠ¡
  - Avatar ç®¡ç†é›†æˆ
  - WebRTC ä»£ç†æ”¯æŒ
